{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow Implementation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO9XMWNtvge+R4/yZRxvVbA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B25XDLa5DSRj"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import datetime\n",
        "\n",
        "# Line 1 - 24번까지가 Build Graph하고 각종 계산 장치를 넣어주는 것 \n",
        "# 여기서는 우리가 Weight값, Bias값 그리고 그 웨이트들을 계산한 것을 hypthesis로 표현한 다음에\n",
        "# 그 값을 통해서 그래프를 만들려고 함. \n",
        "x_train = [1, 2, 3]\n",
        "y_train = [1, 2, 3]\n",
        "\n",
        "# H(x) = Wx + b 를 밑으로 말했을 때 어떻게 표현하냐면 아래와 같이 표현 할 수 있다.\n",
        "W = tf.Variable(tf.random.normal([1]), name = 'weight')\n",
        "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
        "\n",
        "hypothesis = x_train * W + b\n",
        "\n",
        "# Cost의 값을 아래와 같이 계산ㅎ 준 것.\n",
        "# Cost는 graph의 값과 y 값이 얼마나 차이가 있는지를 보여주는 값이고 그 차이를 계산하는 것을\n",
        "# 말함 \n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
        "\n",
        "# Minimize 하는 과정이고, 알에서는 GradientDescent로 만듬 \n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Seesion\n",
        "sess = tf.Session()\n",
        "# Initializes global \n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line\n",
        "for step in range(2001):\n",
        "  sess.run(train)\n",
        "  if step % 20 == 0:\n",
        "      print(step, sess.run(cost), sess.run(W), sess.run(b))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB2OL-O-J8dk"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import datetime\n",
        "\n",
        "# Line 1 - 24번까지가 Build Graph하고 각종 계산 장치를 넣어주는 것 \n",
        "# 여기서는 우리가 Weight값, Bias값 그리고 그 웨이트들을 계산한 것을 hypthesis로 표현한 다음에\n",
        "# 그 값을 통해서 그래프를 만들려고 함. \n",
        "\n",
        "\n",
        "# H(x) = Wx + b 를 밑으로 말했을 때 어떻게 표현하냐면 아래와 같이 표현 할 수 있다.\n",
        "# Placeholder를 쓰는 이유는 위의 코드와 똑같지만, 아래와 같이 값들을 나중에 넣을 수 있기 때문에 쓴다. \n",
        "W = tf.Variable(tf.random.normal([1]), name = 'weight')\n",
        "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
        "X = tf.placeholder(tf.float32, shape=[None])\n",
        "Y = tf.placeholder(tf.float32, shape=[None])\n",
        "\n",
        "hypothesis = X * W + b\n",
        "\n",
        "# Cost의 값을 아래와 같이 계산ㅎ 준 것.\n",
        "# Cost는 graph의 값과 y 값이 얼마나 차이가 있는지를 보여주는 값이고 그 차이를 계산하는 것을\n",
        "# 말함 \n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize 하는 과정이고, 알에서는 GradientDescent로 만듬 \n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "train = optimizer.minimize(cost)\n",
        "\n",
        "# Seesion\n",
        "sess = tf.Session()\n",
        "# Initializes global \n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# Fit the line\n",
        "for step in range(2001):\n",
        "  cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
        "      feed_dict={X: [1, 2, 3, 4, 5], \n",
        "                  Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
        "  if step % 20 == 0:\n",
        "      print(step, cost_val, W_val, b_val)\n",
        "\n",
        "print(sess.run(hypothesis, feed_dict={X: [2.5, 3.67]}))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}